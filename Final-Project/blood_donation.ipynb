{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "blood_donation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1469549798e34b85a5a31d5d33649904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25044c664a4d41008db6e9dea95cb924",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8435277296094300bed9839eb1ec883c",
              "IPY_MODEL_56ed1f3f5b4f4920882964fa17993926"
            ]
          }
        },
        "25044c664a4d41008db6e9dea95cb924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8435277296094300bed9839eb1ec883c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4a163f388cc4e71b4112dc87bfe2ff3",
            "_dom_classes": [],
            "description": "Optimization Progress: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 120,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 120,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c354fc7988104036b77e625663d01a5f"
          }
        },
        "56ed1f3f5b4f4920882964fa17993926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8b6cd0dc1384fc0a8b9b28e40b62425",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 120/120 [00:04&lt;00:00, 22.21pipeline/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2cf9c2b45cf477c906bd9c3b768e281"
          }
        },
        "d4a163f388cc4e71b4112dc87bfe2ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c354fc7988104036b77e625663d01a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8b6cd0dc1384fc0a8b9b28e40b62425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2cf9c2b45cf477c906bd9c3b768e281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjhQL_HLraeT"
      },
      "source": [
        "# Predict Blood Donation for Future Expectancy\n",
        "\n",
        "\n",
        "Forecasting blood supply is a serious and recurrent problem for blood collection managers: in January 2019, \"Nationwide, the Red Cross saw 27,000 fewer blood donations over the holidays than they see at other times of the year.\" Machine learning can be used to learn the patterns in the data to help to predict future blood donations and therefore save more lives.\n",
        "\n",
        "In this Project, we will work with data collected from the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes its blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. The dataset, obtained from the UCI Machine Learning Repository, consists of a random sample of 748 donors. Our task is to predict if a blood donor will donate within a given time window. We will look at the full model-building process: from inspecting the dataset to using the tpot library to automate our Machine Learning pipeline.\n",
        "\n",
        "Project Tasks\n",
        "Inspecting transfusion.data file\n",
        "\n",
        "2. Loading the blood donations data\n",
        "\n",
        "3. Inspecting transfusion DataFrame\n",
        "\n",
        "4. Creating target column\n",
        "\n",
        "5. Checking target incidence\n",
        "\n",
        "6. Splitting transfusion into train and test datasets\n",
        "\n",
        "7. Selecting model using TPOT\n",
        "\n",
        "8. Checking the variance\n",
        "\n",
        "9. Log normalization\n",
        "\n",
        "10. Training the linear regression model\n",
        "\n",
        "11. Conclusion\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2phKU3f6raeZ"
      },
      "source": [
        "## 1. Inspecting transfusion.data file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_gkTiefraed"
      },
      "source": [
        "Blood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. According to WebMD, \"about 5 million Americans need a blood transfusion every year\".\n",
        "\n",
        "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive. We want to predict whether or not a donor will give blood the next time the vehicle comes to campus.\n",
        "\n",
        "The data is stored in datasets/transfusion.data and it is structured according to RFMTC marketing model (a variation of RFM). We'll explore what that means later in this notebook. First, let's inspect the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFhcY--yraeh",
        "outputId": "6fb99c89-c5a4-4dbd-cff6-6a68075998fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "f = open('transfusion.data',\"r\")\n",
        "print(f.read())\n",
        "f.close()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recency (months),Frequency (times),Monetary (c.c. blood),Time (months),\"whether he/she donated blood in March 2007\"\n",
            "2 ,50,12500,98 ,1\n",
            "0 ,13,3250,28 ,1\n",
            "1 ,16,4000,35 ,1\n",
            "2 ,20,5000,45 ,1\n",
            "1 ,24,6000,77 ,0\n",
            "4 ,4,1000,4 ,0\n",
            "2 ,7,1750,14 ,1\n",
            "1 ,12,3000,35 ,0\n",
            "2 ,9,2250,22 ,1\n",
            "5 ,46,11500,98 ,1\n",
            "4 ,23,5750,58 ,0\n",
            "0 ,3,750,4 ,0\n",
            "2 ,10,2500,28 ,1\n",
            "1 ,13,3250,47 ,0\n",
            "2 ,6,1500,15 ,1\n",
            "2 ,5,1250,11 ,1\n",
            "2 ,14,3500,48 ,1\n",
            "2 ,15,3750,49 ,1\n",
            "2 ,6,1500,15 ,1\n",
            "2 ,3,750,4 ,1\n",
            "2 ,3,750,4 ,1\n",
            "4 ,11,2750,28 ,0\n",
            "2 ,6,1500,16 ,1\n",
            "2 ,6,1500,16 ,1\n",
            "9 ,9,2250,16 ,0\n",
            "4 ,14,3500,40 ,0\n",
            "4 ,6,1500,14 ,0\n",
            "4 ,12,3000,34 ,1\n",
            "4 ,5,1250,11 ,1\n",
            "4 ,8,2000,21 ,0\n",
            "1 ,14,3500,58 ,0\n",
            "4 ,10,2500,28 ,1\n",
            "4 ,10,2500,28 ,1\n",
            "4 ,9,2250,26 ,1\n",
            "2 ,16,4000,64 ,0\n",
            "2 ,8,2000,28 ,1\n",
            "2 ,12,3000,47 ,1\n",
            "4 ,6,1500,16 ,1\n",
            "2 ,14,3500,57 ,1\n",
            "4 ,7,1750,22 ,1\n",
            "2 ,13,3250,53 ,1\n",
            "2 ,5,1250,16 ,0\n",
            "2 ,5,1250,16 ,1\n",
            "2 ,5,1250,16 ,0\n",
            "4 ,20,5000,69 ,1\n",
            "4 ,9,2250,28 ,1\n",
            "2 ,9,2250,36 ,0\n",
            "2 ,2,500,2 ,0\n",
            "2 ,2,500,2 ,0\n",
            "2 ,2,500,2 ,0\n",
            "2 ,11,2750,46 ,0\n",
            "2 ,11,2750,46 ,1\n",
            "2 ,6,1500,22 ,0\n",
            "2 ,12,3000,52 ,0\n",
            "4 ,5,1250,14 ,1\n",
            "4 ,19,4750,69 ,1\n",
            "4 ,8,2000,26 ,1\n",
            "2 ,7,1750,28 ,1\n",
            "2 ,16,4000,81 ,0\n",
            "3 ,6,1500,21 ,0\n",
            "2 ,7,1750,29 ,0\n",
            "2 ,8,2000,35 ,1\n",
            "2 ,10,2500,49 ,0\n",
            "4 ,5,1250,16 ,1\n",
            "2 ,3,750,9 ,1\n",
            "3 ,16,4000,74 ,0\n",
            "2 ,4,1000,14 ,1\n",
            "0 ,2,500,4 ,0\n",
            "4 ,7,1750,25 ,0\n",
            "1 ,9,2250,51 ,0\n",
            "2 ,4,1000,16 ,0\n",
            "2 ,4,1000,16 ,0\n",
            "4 ,17,4250,71 ,1\n",
            "2 ,2,500,4 ,0\n",
            "2 ,2,500,4 ,1\n",
            "2 ,2,500,4 ,1\n",
            "2 ,4,1000,16 ,1\n",
            "2 ,2,500,4 ,0\n",
            "2 ,2,500,4 ,0\n",
            "2 ,2,500,4 ,0\n",
            "4 ,6,1500,23 ,1\n",
            "2 ,4,1000,16 ,0\n",
            "2 ,4,1000,16 ,0\n",
            "2 ,4,1000,16 ,0\n",
            "2 ,6,1500,28 ,1\n",
            "2 ,6,1500,28 ,0\n",
            "4 ,2,500,4 ,0\n",
            "4 ,2,500,4 ,0\n",
            "4 ,2,500,4 ,0\n",
            "2 ,7,1750,35 ,1\n",
            "4 ,2,500,4 ,1\n",
            "4 ,2,500,4 ,0\n",
            "4 ,2,500,4 ,0\n",
            "4 ,2,500,4 ,0\n",
            "12 ,11,2750,23 ,0\n",
            "4 ,7,1750,28 ,0\n",
            "3 ,17,4250,86 ,0\n",
            "4 ,9,2250,38 ,1\n",
            "4 ,4,1000,14 ,1\n",
            "5 ,7,1750,26 ,1\n",
            "4 ,8,2000,34 ,1\n",
            "2 ,13,3250,76 ,1\n",
            "4 ,9,2250,40 ,0\n",
            "2 ,5,1250,26 ,0\n",
            "2 ,5,1250,26 ,0\n",
            "6 ,17,4250,70 ,0\n",
            "0 ,8,2000,59 ,0\n",
            "3 ,5,1250,26 ,0\n",
            "2 ,3,750,14 ,0\n",
            "2 ,10,2500,64 ,0\n",
            "4 ,5,1250,23 ,1\n",
            "4 ,9,2250,46 ,0\n",
            "4 ,5,1250,23 ,0\n",
            "4 ,8,2000,40 ,1\n",
            "2 ,12,3000,82 ,0\n",
            "11 ,24,6000,64 ,0\n",
            "2 ,7,1750,46 ,1\n",
            "4 ,11,2750,61 ,0\n",
            "1 ,7,1750,57 ,0\n",
            "2 ,11,2750,79 ,1\n",
            "2 ,3,750,16 ,1\n",
            "4 ,5,1250,26 ,1\n",
            "2 ,6,1500,41 ,1\n",
            "2 ,5,1250,33 ,1\n",
            "2 ,4,1000,26 ,0\n",
            "2 ,5,1250,34 ,0\n",
            "4 ,8,2000,46 ,1\n",
            "2 ,4,1000,26 ,0\n",
            "4 ,8,2000,48 ,1\n",
            "2 ,2,500,10 ,1\n",
            "4 ,5,1250,28 ,0\n",
            "2 ,12,3000,95 ,0\n",
            "2 ,2,500,10 ,0\n",
            "4 ,6,1500,35 ,0\n",
            "2 ,11,2750,88 ,0\n",
            "2 ,3,750,19 ,0\n",
            "2 ,5,1250,37 ,0\n",
            "2 ,12,3000,98 ,0\n",
            "9 ,5,1250,19 ,0\n",
            "2 ,2,500,11 ,0\n",
            "2 ,9,2250,74 ,0\n",
            "5 ,14,3500,86 ,0\n",
            "4 ,3,750,16 ,0\n",
            "4 ,3,750,16 ,0\n",
            "4 ,2,500,9 ,1\n",
            "4 ,3,750,16 ,1\n",
            "6 ,3,750,14 ,0\n",
            "2 ,2,500,11 ,0\n",
            "2 ,2,500,11 ,1\n",
            "2 ,2,500,11 ,0\n",
            "2 ,7,1750,58 ,1\n",
            "4 ,6,1500,39 ,0\n",
            "4 ,11,2750,78 ,0\n",
            "2 ,1,250,2 ,1\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,1\n",
            "2 ,1,250,2 ,1\n",
            "2 ,1,250,2 ,1\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "11 ,10,2500,35 ,0\n",
            "11 ,4,1000,16 ,1\n",
            "4 ,5,1250,33 ,1\n",
            "4 ,6,1500,41 ,1\n",
            "2 ,3,750,22 ,0\n",
            "4 ,4,1000,26 ,1\n",
            "10 ,4,1000,16 ,0\n",
            "2 ,4,1000,35 ,0\n",
            "4 ,12,3000,88 ,0\n",
            "13 ,8,2000,26 ,0\n",
            "11 ,9,2250,33 ,0\n",
            "4 ,5,1250,34 ,0\n",
            "4 ,4,1000,26 ,0\n",
            "8 ,15,3750,77 ,0\n",
            "4 ,5,1250,35 ,1\n",
            "4 ,7,1750,52 ,0\n",
            "4 ,7,1750,52 ,0\n",
            "2 ,4,1000,35 ,0\n",
            "11 ,11,2750,42 ,0\n",
            "2 ,2,500,14 ,0\n",
            "2 ,5,1250,47 ,1\n",
            "9 ,8,2000,38 ,1\n",
            "4 ,6,1500,47 ,0\n",
            "11 ,7,1750,29 ,0\n",
            "9 ,9,2250,45 ,0\n",
            "4 ,6,1500,52 ,0\n",
            "4 ,7,1750,58 ,0\n",
            "6 ,2,500,11 ,1\n",
            "4 ,7,1750,58 ,0\n",
            "11 ,9,2250,38 ,0\n",
            "11 ,6,1500,26 ,0\n",
            "2 ,2,500,16 ,0\n",
            "2 ,7,1750,76 ,0\n",
            "11 ,6,1500,27 ,0\n",
            "11 ,3,750,14 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,0\n",
            "4 ,3,750,24 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,0\n",
            "10 ,8,2000,39 ,0\n",
            "14 ,7,1750,26 ,0\n",
            "8 ,10,2500,63 ,0\n",
            "11 ,3,750,15 ,0\n",
            "4 ,2,500,14 ,0\n",
            "2 ,4,1000,43 ,0\n",
            "8 ,9,2250,58 ,0\n",
            "8 ,8,2000,52 ,1\n",
            "11 ,22,5500,98 ,0\n",
            "4 ,3,750,25 ,1\n",
            "11 ,17,4250,79 ,1\n",
            "9 ,2,500,11 ,0\n",
            "4 ,5,1250,46 ,0\n",
            "11 ,12,3000,58 ,0\n",
            "7 ,12,3000,86 ,0\n",
            "11 ,2,500,11 ,0\n",
            "11 ,2,500,11 ,0\n",
            "11 ,2,500,11 ,0\n",
            "2 ,6,1500,75 ,0\n",
            "11 ,8,2000,41 ,1\n",
            "11 ,3,750,16 ,1\n",
            "12 ,13,3250,59 ,0\n",
            "2 ,3,750,35 ,0\n",
            "16 ,8,2000,28 ,0\n",
            "11 ,7,1750,37 ,0\n",
            "4 ,3,750,28 ,0\n",
            "12 ,12,3000,58 ,0\n",
            "4 ,4,1000,41 ,0\n",
            "11 ,14,3500,73 ,1\n",
            "2 ,2,500,23 ,0\n",
            "2 ,3,750,38 ,1\n",
            "4 ,5,1250,58 ,0\n",
            "4 ,4,1000,43 ,1\n",
            "3 ,2,500,23 ,0\n",
            "11 ,8,2000,46 ,0\n",
            "4 ,7,1750,82 ,0\n",
            "13 ,4,1000,21 ,0\n",
            "16 ,11,2750,40 ,0\n",
            "16 ,7,1750,28 ,0\n",
            "7 ,2,500,16 ,0\n",
            "4 ,5,1250,58 ,0\n",
            "4 ,5,1250,58 ,0\n",
            "4 ,4,1000,46 ,0\n",
            "14 ,13,3250,57 ,0\n",
            "4 ,3,750,34 ,0\n",
            "14 ,18,4500,78 ,0\n",
            "11 ,8,2000,48 ,0\n",
            "14 ,16,4000,70 ,0\n",
            "14 ,4,1000,22 ,1\n",
            "14 ,5,1250,26 ,0\n",
            "8 ,2,500,16 ,0\n",
            "11 ,5,1250,33 ,0\n",
            "11 ,2,500,14 ,0\n",
            "4 ,2,500,23 ,0\n",
            "9 ,2,500,16 ,1\n",
            "14 ,5,1250,28 ,1\n",
            "14 ,3,750,19 ,1\n",
            "14 ,4,1000,23 ,1\n",
            "16 ,12,3000,50 ,0\n",
            "11 ,4,1000,28 ,0\n",
            "11 ,5,1250,35 ,0\n",
            "11 ,5,1250,35 ,0\n",
            "2 ,4,1000,70 ,0\n",
            "14 ,5,1250,28 ,0\n",
            "14 ,2,500,14 ,0\n",
            "14 ,2,500,14 ,0\n",
            "14 ,2,500,14 ,0\n",
            "14 ,2,500,14 ,0\n",
            "14 ,2,500,14 ,0\n",
            "14 ,2,500,14 ,0\n",
            "2 ,3,750,52 ,0\n",
            "14 ,6,1500,34 ,0\n",
            "11 ,5,1250,37 ,1\n",
            "4 ,5,1250,74 ,0\n",
            "11 ,3,750,23 ,0\n",
            "16 ,4,1000,23 ,0\n",
            "16 ,3,750,19 ,0\n",
            "11 ,5,1250,38 ,0\n",
            "11 ,2,500,16 ,0\n",
            "12 ,9,2250,60 ,0\n",
            "9 ,1,250,9 ,0\n",
            "9 ,1,250,9 ,0\n",
            "4 ,2,500,29 ,0\n",
            "11 ,2,500,17 ,0\n",
            "14 ,4,1000,26 ,0\n",
            "11 ,9,2250,72 ,1\n",
            "11 ,5,1250,41 ,0\n",
            "15 ,16,4000,82 ,0\n",
            "9 ,5,1250,51 ,1\n",
            "11 ,4,1000,34 ,0\n",
            "14 ,8,2000,50 ,1\n",
            "16 ,7,1750,38 ,0\n",
            "14 ,2,500,16 ,0\n",
            "2 ,2,500,41 ,0\n",
            "14 ,16,4000,98 ,0\n",
            "14 ,4,1000,28 ,1\n",
            "16 ,7,1750,39 ,0\n",
            "14 ,7,1750,47 ,0\n",
            "16 ,6,1500,35 ,0\n",
            "16 ,6,1500,35 ,1\n",
            "11 ,7,1750,62 ,1\n",
            "16 ,2,500,16 ,0\n",
            "16 ,3,750,21 ,1\n",
            "11 ,3,750,28 ,0\n",
            "11 ,7,1750,64 ,0\n",
            "11 ,1,250,11 ,1\n",
            "9 ,3,750,34 ,0\n",
            "14 ,4,1000,30 ,0\n",
            "23 ,38,9500,98 ,0\n",
            "11 ,6,1500,58 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,2,500,21 ,0\n",
            "11 ,5,1250,50 ,0\n",
            "11 ,2,500,21 ,0\n",
            "16 ,4,1000,28 ,0\n",
            "4 ,2,500,41 ,0\n",
            "16 ,6,1500,40 ,0\n",
            "14 ,3,750,26 ,0\n",
            "9 ,2,500,26 ,0\n",
            "21 ,16,4000,64 ,0\n",
            "14 ,6,1500,51 ,0\n",
            "11 ,2,500,24 ,0\n",
            "4 ,3,750,71 ,0\n",
            "21 ,13,3250,57 ,0\n",
            "11 ,6,1500,71 ,0\n",
            "14 ,2,500,21 ,1\n",
            "23 ,15,3750,57 ,0\n",
            "14 ,4,1000,38 ,0\n",
            "11 ,2,500,26 ,0\n",
            "16 ,5,1250,40 ,1\n",
            "4 ,2,500,51 ,1\n",
            "14 ,3,750,31 ,0\n",
            "4 ,2,500,52 ,0\n",
            "9 ,4,1000,65 ,0\n",
            "14 ,4,1000,40 ,0\n",
            "11 ,3,750,40 ,1\n",
            "14 ,5,1250,50 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,7,1750,72 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "9 ,3,750,52 ,0\n",
            "14 ,7,1750,73 ,0\n",
            "11 ,4,1000,58 ,0\n",
            "11 ,4,1000,59 ,0\n",
            "4 ,2,500,59 ,0\n",
            "11 ,4,1000,61 ,0\n",
            "16 ,4,1000,40 ,0\n",
            "16 ,10,2500,89 ,0\n",
            "21 ,2,500,21 ,1\n",
            "21 ,3,750,26 ,0\n",
            "16 ,8,2000,76 ,0\n",
            "21 ,3,750,26 ,1\n",
            "18 ,2,500,23 ,0\n",
            "23 ,5,1250,33 ,0\n",
            "23 ,8,2000,46 ,0\n",
            "16 ,3,750,34 ,0\n",
            "14 ,5,1250,64 ,0\n",
            "14 ,3,750,41 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,4,1000,45 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,2,500,26 ,0\n",
            "21 ,2,500,23 ,0\n",
            "16 ,2,500,27 ,0\n",
            "21 ,2,500,23 ,0\n",
            "21 ,2,500,23 ,0\n",
            "14 ,4,1000,57 ,0\n",
            "16 ,5,1250,60 ,0\n",
            "23 ,2,500,23 ,0\n",
            "14 ,5,1250,74 ,0\n",
            "23 ,3,750,28 ,0\n",
            "16 ,3,750,40 ,0\n",
            "9 ,2,500,52 ,0\n",
            "9 ,2,500,52 ,0\n",
            "16 ,7,1750,87 ,1\n",
            "14 ,4,1000,64 ,0\n",
            "14 ,2,500,35 ,0\n",
            "16 ,7,1750,93 ,0\n",
            "21 ,2,500,25 ,0\n",
            "14 ,3,750,52 ,0\n",
            "23 ,14,3500,93 ,0\n",
            "18 ,8,2000,95 ,0\n",
            "16 ,3,750,46 ,0\n",
            "11 ,3,750,76 ,0\n",
            "11 ,2,500,52 ,0\n",
            "11 ,3,750,76 ,0\n",
            "23 ,12,3000,86 ,0\n",
            "21 ,3,750,35 ,0\n",
            "23 ,2,500,26 ,0\n",
            "23 ,2,500,26 ,0\n",
            "23 ,8,2000,64 ,0\n",
            "16 ,3,750,50 ,0\n",
            "23 ,3,750,33 ,0\n",
            "21 ,3,750,38 ,0\n",
            "23 ,2,500,28 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,1\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,5,1250,60 ,0\n",
            "23 ,4,1000,45 ,0\n",
            "21 ,4,1000,52 ,0\n",
            "22 ,1,250,22 ,1\n",
            "11 ,2,500,70 ,0\n",
            "23 ,5,1250,58 ,0\n",
            "23 ,3,750,40 ,0\n",
            "23 ,3,750,41 ,0\n",
            "14 ,3,750,83 ,0\n",
            "21 ,2,500,35 ,0\n",
            "26 ,5,1250,49 ,1\n",
            "23 ,6,1500,70 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,4,1000,53 ,0\n",
            "21 ,6,1500,86 ,0\n",
            "23 ,3,750,48 ,0\n",
            "21 ,2,500,41 ,0\n",
            "21 ,3,750,64 ,0\n",
            "16 ,2,500,70 ,0\n",
            "21 ,3,750,70 ,0\n",
            "23 ,4,1000,87 ,0\n",
            "23 ,3,750,89 ,0\n",
            "23 ,2,500,87 ,0\n",
            "35 ,3,750,64 ,0\n",
            "38 ,1,250,38 ,0\n",
            "38 ,1,250,38 ,0\n",
            "40 ,1,250,40 ,0\n",
            "74 ,1,250,74 ,0\n",
            "2 ,43,10750,86 ,1\n",
            "6 ,22,5500,28 ,1\n",
            "2 ,34,8500,77 ,1\n",
            "2 ,44,11000,98 ,0\n",
            "0 ,26,6500,76 ,1\n",
            "2 ,41,10250,98 ,1\n",
            "3 ,21,5250,42 ,1\n",
            "2 ,11,2750,23 ,0\n",
            "2 ,21,5250,52 ,1\n",
            "2 ,13,3250,32 ,1\n",
            "4 ,4,1000,4 ,1\n",
            "2 ,11,2750,26 ,0\n",
            "2 ,11,2750,28 ,0\n",
            "3 ,14,3500,35 ,0\n",
            "4 ,16,4000,38 ,1\n",
            "4 ,6,1500,14 ,0\n",
            "3 ,5,1250,12 ,1\n",
            "4 ,33,8250,98 ,1\n",
            "3 ,10,2500,33 ,1\n",
            "4 ,10,2500,28 ,1\n",
            "2 ,11,2750,40 ,1\n",
            "2 ,11,2750,41 ,1\n",
            "4 ,13,3250,39 ,1\n",
            "1 ,10,2500,43 ,1\n",
            "4 ,9,2250,28 ,0\n",
            "2 ,4,1000,11 ,0\n",
            "2 ,5,1250,16 ,1\n",
            "2 ,15,3750,64 ,0\n",
            "5 ,24,6000,79 ,0\n",
            "2 ,6,1500,22 ,1\n",
            "4 ,5,1250,16 ,1\n",
            "2 ,4,1000,14 ,1\n",
            "4 ,8,2000,28 ,0\n",
            "2 ,4,1000,14 ,0\n",
            "2 ,6,1500,26 ,0\n",
            "4 ,5,1250,16 ,1\n",
            "2 ,7,1750,32 ,1\n",
            "2 ,6,1500,26 ,1\n",
            "2 ,8,2000,38 ,1\n",
            "2 ,2,500,4 ,1\n",
            "2 ,6,1500,28 ,1\n",
            "2 ,10,2500,52 ,0\n",
            "4 ,16,4000,70 ,1\n",
            "4 ,2,500,4 ,1\n",
            "1 ,14,3500,95 ,0\n",
            "4 ,2,500,4 ,1\n",
            "7 ,14,3500,48 ,0\n",
            "2 ,3,750,11 ,0\n",
            "2 ,12,3000,70 ,1\n",
            "4 ,7,1750,32 ,1\n",
            "4 ,4,1000,16 ,0\n",
            "2 ,6,1500,35 ,1\n",
            "4 ,6,1500,28 ,1\n",
            "2 ,3,750,14 ,0\n",
            "2 ,4,1000,23 ,0\n",
            "4 ,4,1000,18 ,0\n",
            "5 ,6,1500,28 ,0\n",
            "4 ,6,1500,30 ,0\n",
            "14 ,5,1250,14 ,0\n",
            "3 ,8,2000,50 ,0\n",
            "4 ,11,2750,64 ,1\n",
            "4 ,9,2250,52 ,0\n",
            "4 ,16,4000,98 ,1\n",
            "7 ,10,2500,47 ,0\n",
            "4 ,14,3500,86 ,0\n",
            "2 ,9,2250,75 ,0\n",
            "4 ,6,1500,35 ,0\n",
            "4 ,9,2250,55 ,0\n",
            "4 ,6,1500,35 ,1\n",
            "2 ,6,1500,45 ,0\n",
            "2 ,6,1500,47 ,0\n",
            "4 ,2,500,9 ,0\n",
            "2 ,2,500,11 ,1\n",
            "2 ,2,500,11 ,0\n",
            "2 ,2,500,11 ,1\n",
            "4 ,6,1500,38 ,1\n",
            "3 ,4,1000,29 ,1\n",
            "9 ,9,2250,38 ,0\n",
            "11 ,5,1250,18 ,0\n",
            "2 ,3,750,21 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,1\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,1\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "2 ,1,250,2 ,0\n",
            "11 ,11,2750,38 ,0\n",
            "2 ,3,750,22 ,0\n",
            "9 ,11,2750,49 ,1\n",
            "5 ,11,2750,75 ,0\n",
            "3 ,5,1250,38 ,0\n",
            "3 ,1,250,3 ,1\n",
            "4 ,6,1500,43 ,0\n",
            "2 ,3,750,24 ,0\n",
            "12 ,11,2750,39 ,0\n",
            "2 ,2,500,14 ,0\n",
            "4 ,6,1500,46 ,0\n",
            "9 ,3,750,14 ,0\n",
            "14 ,8,2000,26 ,0\n",
            "4 ,2,500,13 ,0\n",
            "4 ,11,2750,95 ,0\n",
            "2 ,7,1750,77 ,0\n",
            "2 ,7,1750,77 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,1,250,4 ,1\n",
            "4 ,1,250,4 ,0\n",
            "4 ,7,1750,62 ,0\n",
            "4 ,1,250,4 ,0\n",
            "4 ,4,1000,34 ,1\n",
            "11 ,6,1500,28 ,0\n",
            "13 ,3,750,14 ,1\n",
            "7 ,5,1250,35 ,0\n",
            "9 ,9,2250,54 ,0\n",
            "11 ,2,500,11 ,0\n",
            "2 ,5,1250,63 ,0\n",
            "7 ,11,2750,89 ,0\n",
            "8 ,9,2250,64 ,0\n",
            "2 ,2,500,22 ,0\n",
            "6 ,3,750,26 ,0\n",
            "12 ,15,3750,71 ,0\n",
            "13 ,3,750,16 ,0\n",
            "11 ,16,4000,89 ,0\n",
            "4 ,5,1250,58 ,0\n",
            "14 ,7,1750,35 ,0\n",
            "11 ,4,1000,27 ,0\n",
            "7 ,9,2250,89 ,1\n",
            "11 ,8,2000,52 ,1\n",
            "7 ,5,1250,52 ,0\n",
            "11 ,6,1500,41 ,0\n",
            "10 ,5,1250,38 ,0\n",
            "14 ,2,500,14 ,1\n",
            "14 ,2,500,14 ,0\n",
            "14 ,2,500,14 ,0\n",
            "2 ,2,500,33 ,0\n",
            "11 ,3,750,23 ,0\n",
            "14 ,8,2000,46 ,0\n",
            "9 ,1,250,9 ,0\n",
            "16 ,5,1250,27 ,0\n",
            "14 ,4,1000,26 ,0\n",
            "4 ,2,500,30 ,0\n",
            "14 ,3,750,21 ,0\n",
            "16 ,16,4000,77 ,0\n",
            "4 ,2,500,31 ,0\n",
            "14 ,8,2000,50 ,0\n",
            "11 ,3,750,26 ,0\n",
            "14 ,7,1750,45 ,0\n",
            "15 ,5,1250,33 ,0\n",
            "16 ,2,500,16 ,0\n",
            "16 ,3,750,21 ,0\n",
            "11 ,8,2000,72 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,0\n",
            "11 ,1,250,11 ,1\n",
            "11 ,1,250,11 ,0\n",
            "2 ,3,750,75 ,1\n",
            "2 ,3,750,77 ,0\n",
            "16 ,4,1000,28 ,0\n",
            "16 ,15,3750,87 ,0\n",
            "16 ,14,3500,83 ,0\n",
            "16 ,10,2500,62 ,0\n",
            "16 ,3,750,23 ,0\n",
            "14 ,3,750,26 ,0\n",
            "23 ,19,4750,62 ,0\n",
            "11 ,7,1750,75 ,0\n",
            "14 ,3,750,28 ,0\n",
            "20 ,14,3500,69 ,1\n",
            "4 ,2,500,46 ,0\n",
            "11 ,2,500,25 ,0\n",
            "11 ,3,750,37 ,0\n",
            "16 ,4,1000,33 ,0\n",
            "21 ,7,1750,38 ,0\n",
            "13 ,7,1750,76 ,0\n",
            "16 ,6,1500,50 ,0\n",
            "14 ,3,750,33 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "14 ,1,250,14 ,0\n",
            "17 ,7,1750,58 ,1\n",
            "14 ,3,750,35 ,0\n",
            "14 ,3,750,35 ,0\n",
            "16 ,7,1750,64 ,0\n",
            "21 ,2,500,21 ,0\n",
            "16 ,3,750,35 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "16 ,1,250,16 ,0\n",
            "14 ,2,500,29 ,0\n",
            "11 ,4,1000,74 ,0\n",
            "11 ,2,500,38 ,1\n",
            "21 ,6,1500,48 ,0\n",
            "23 ,2,500,23 ,0\n",
            "23 ,6,1500,45 ,0\n",
            "14 ,2,500,35 ,1\n",
            "16 ,6,1500,81 ,0\n",
            "16 ,4,1000,58 ,0\n",
            "16 ,5,1250,71 ,0\n",
            "21 ,2,500,26 ,0\n",
            "21 ,3,750,35 ,0\n",
            "21 ,3,750,35 ,0\n",
            "23 ,8,2000,69 ,0\n",
            "21 ,3,750,38 ,0\n",
            "23 ,3,750,35 ,0\n",
            "21 ,3,750,40 ,0\n",
            "23 ,2,500,28 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "25 ,6,1500,50 ,0\n",
            "21 ,1,250,21 ,0\n",
            "21 ,1,250,21 ,0\n",
            "23 ,3,750,39 ,0\n",
            "21 ,2,500,33 ,0\n",
            "14 ,3,750,79 ,0\n",
            "23 ,1,250,23 ,1\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,4,1000,52 ,0\n",
            "23 ,1,250,23 ,0\n",
            "23 ,7,1750,88 ,0\n",
            "16 ,3,750,86 ,0\n",
            "23 ,2,500,38 ,0\n",
            "21 ,2,500,52 ,0\n",
            "23 ,3,750,62 ,0\n",
            "39 ,1,250,39 ,0\n",
            "72 ,1,250,72 ,0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRwa5MCRraev"
      },
      "source": [
        "\n",
        "## 2. Loading the blood donations data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYVw1MZwraey"
      },
      "source": [
        "We now know that we are working with a typical CSV file (i.e., the delimiter is ,, etc.). We proceed to loading the data into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTCilef1rae0",
        "outputId": "abd946dd-bd9d-41f2-cace-0373c693bf87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"transfusion.data\")\n",
        "df.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recency (months)</th>\n",
              "      <th>Frequency (times)</th>\n",
              "      <th>Monetary (c.c. blood)</th>\n",
              "      <th>Time (months)</th>\n",
              "      <th>whether he/she donated blood in March 2007</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>12500</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>3250</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4000</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>5000</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6000</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1750</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3000</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>2250</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>46</td>\n",
              "      <td>11500</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Recency (months)  ...  whether he/she donated blood in March 2007\n",
              "0                 2  ...                                           1\n",
              "1                 0  ...                                           1\n",
              "2                 1  ...                                           1\n",
              "3                 2  ...                                           1\n",
              "4                 1  ...                                           0\n",
              "5                 4  ...                                           0\n",
              "6                 2  ...                                           1\n",
              "7                 1  ...                                           0\n",
              "8                 2  ...                                           1\n",
              "9                 5  ...                                           1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWD60mmOrae_"
      },
      "source": [
        "## 3. Inspecting transfusion DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6T2YOTmrafE"
      },
      "source": [
        "Let's briefly return to our discussion of RFM model. RFM stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying your best customers. In our case, our customers are blood donors.\n",
        "\n",
        "RFMTC is a variation of the RFM model. Below is a description of what each column means in our dataset:\n",
        "R (Recency - months since the last donation)\n",
        "\n",
        "F (Frequency - total number of donation)\n",
        "\n",
        "M (Monetary - total blood donated in c.c.)\n",
        "\n",
        "T (Time - months since the first donation)\n",
        "\n",
        "a binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)\n",
        "\n",
        "It looks like every column in our DataFrame has the numeric type, which is exactly what we want when building a machine learning model. Let's verify our hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIwdcfRJrafG",
        "outputId": "7696fa45-9d09-49d7-84dd-5bab0d9f60e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape\n",
        "print(\"The dataframe has {} rows and {} columns.\".format(df.shape[0],df.shape[1]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataframe has 748 rows and 5 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01mneO0MrafS",
        "outputId": "8ca7cbfa-7314-40ab-8727-daac2a01e05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 748 entries, 0 to 747\n",
            "Data columns (total 5 columns):\n",
            " #   Column                                      Non-Null Count  Dtype\n",
            "---  ------                                      --------------  -----\n",
            " 0   Recency (months)                            748 non-null    int64\n",
            " 1   Frequency (times)                           748 non-null    int64\n",
            " 2   Monetary (c.c. blood)                       748 non-null    int64\n",
            " 3   Time (months)                               748 non-null    int64\n",
            " 4   whether he/she donated blood in March 2007  748 non-null    int64\n",
            "dtypes: int64(5)\n",
            "memory usage: 29.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaN2r_AFrafe"
      },
      "source": [
        "We can see that there is no null value in any column and all the columns are integer type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2v2kZeOrafg"
      },
      "source": [
        "## 4. Creating target column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s22FQyy6rafi"
      },
      "source": [
        "We are aiming to predict the value in whether he/she donated blood in March 2007 column. Let's rename this it to target so that it's more convenient to work with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydIStVLFrafk",
        "outputId": "366dc634-9076-431e-e4e6-6feebbf2b540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.rename(columns={'whether he/she donated blood in March 2007':'target'}, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recency (months)</th>\n",
              "      <th>Frequency (times)</th>\n",
              "      <th>Monetary (c.c. blood)</th>\n",
              "      <th>Time (months)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>12500</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>3250</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4000</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>5000</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>6000</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Recency (months)  Frequency (times)  ...  Time (months)  target\n",
              "0                 2                 50  ...             98       1\n",
              "1                 0                 13  ...             28       1\n",
              "2                 1                 16  ...             35       1\n",
              "3                 2                 20  ...             45       1\n",
              "4                 1                 24  ...             77       0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htP8uKeerafx"
      },
      "source": [
        "## 5. Checking target incidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD8lFZyNrafz"
      },
      "source": [
        "We want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:\n",
        "\n",
        "0 - the donor will not give blood\n",
        "\n",
        "1 - the donor will give blood\n",
        "\n",
        "Target incidence is defined as the number of cases of each individual target value in a dataset. That is, how many 0s in the target column compared to how many 1s? Target incidence gives us an idea of how balanced (or imbalanced) is our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_z6BV51raf1",
        "outputId": "87c8f422-78d6-4342-e383-732f8b200664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['target'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    570\n",
              "1    178\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYc2w3NnragD",
        "outputId": "89d4aeb4-e9b1-4e0b-ea51-517bd89d7171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['target'].value_counts(normalize = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.762032\n",
              "1    0.237968\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-HkIgR7ragN"
      },
      "source": [
        "## 6. Splitting transfusion into train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YoAAFEUragP"
      },
      "source": [
        "We'll now use train_test_split() method to split transfusion DataFrame.\n",
        "\n",
        "Target incidence informed us that in our dataset 0s appear 76% of the time. We want to keep the same structure in train and test datasets, i.e., both datasets must have 0 target incidence of 76%. This is very easy to do using the train_test_split() method from the scikit learn library - all we need to do is specify the stratify parameter. In our case, we'll stratify on the target column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJJHzTj6ragR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(columns = 'target')\n",
        "y = df.target\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42, stratify=df.target)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNGnbK9zraga"
      },
      "source": [
        "## 7. Selecting model using TPOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btepqtkwragc"
      },
      "source": [
        "TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.\n",
        "\n",
        "TPOT will automatically explore hundreds of possible pipelines to find the best one for our dataset. Note, the outcome of this search will be a scikit-learn pipeline, meaning it will include any pre-processing steps as well as the model.\n",
        "\n",
        "We are using TPOT to help us zero in on one model that we can then explore and optimize further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBcPyA2EsDtR",
        "outputId": "00f91821-c7dc-475d-e750-d42af663090f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "!pip install tpot"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/5e/cb87b0257033a7a396e533a634079ee151a239d180efe2a8b1d2e3584d23/TPOT-0.11.5-py3-none-any.whl (82kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆ                            | 10kB 14.3MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.4.1)\n",
            "Collecting update-checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Collecting deap>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/eb/2bd0a32e3ce757fb26264765abbaedd6d4d3640d90219a513aeabd08ee2b/deap-1.3.1-cp36-cp36m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.41.1)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.16.0)\n",
            "Collecting stopit>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp36-none-any.whl size=11956 sha256=d77afbf685ac1d44f3559a2edde5ecc298b9003a8198e487410cdf4e5e90d0dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built stopit\n",
            "Installing collected packages: update-checker, deap, stopit, tpot\n",
            "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.5 update-checker-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLHjdHbkragn",
        "outputId": "c44ac296-a62d-4147-f854-e3814de22681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "1469549798e34b85a5a31d5d33649904",
            "25044c664a4d41008db6e9dea95cb924",
            "8435277296094300bed9839eb1ec883c",
            "56ed1f3f5b4f4920882964fa17993926",
            "d4a163f388cc4e71b4112dc87bfe2ff3",
            "c354fc7988104036b77e625663d01a5f",
            "c8b6cd0dc1384fc0a8b9b28e40b62425",
            "c2cf9c2b45cf477c906bd9c3b768e281"
          ]
        }
      },
      "source": [
        "# Import TPOTClassifier and roc_auc_score\n",
        "from tpot import TPOTClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Instantiate TPOTClassifier\n",
        "tpot = TPOTClassifier(\n",
        "    generations=5,\n",
        "    population_size=20,\n",
        "    verbosity=2,\n",
        "    scoring='roc_auc',\n",
        "    random_state=42,\n",
        "    disable_update_check=True,\n",
        "    config_dict='TPOT light'\n",
        ")\n",
        "tpot.fit(X_train, y_train)\n",
        "\n",
        "# AUC score for tpot model\n",
        "tpot_auc_score = roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])\n",
        "print(f'\\nAUC score: {tpot_auc_score:.3f}')\n",
        "\n",
        "# Print best pipeline steps\n",
        "print('\\nBest pipeline steps:', end='\\n')\n",
        "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
        "    # Print idx and transform\n",
        "    print(f'{idx}. {transform}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1469549798e34b85a5a31d5d33649904",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=120.0, style=ProgressStyle(deâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Generation 1 - Current best internal CV score: 0.7422459184429089\n",
            "Generation 2 - Current best internal CV score: 0.7422459184429089\n",
            "Generation 3 - Current best internal CV score: 0.7422459184429089\n",
            "Generation 4 - Current best internal CV score: 0.7422459184429089\n",
            "Generation 5 - Current best internal CV score: 0.7423330644124079\n",
            "Best pipeline: LogisticRegression(input_matrix, C=0.1, dual=False, penalty=l2)\n",
            "\n",
            "AUC score: 0.785\n",
            "\n",
            "Best pipeline steps:\n",
            "1. LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMqXBNSOrag0"
      },
      "source": [
        "## 8. Checking the variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-mlbV7wrag2"
      },
      "source": [
        "TPOT picked LogisticRegression as the best model for our dataset with no pre-processing steps, giving us the AUC score of 0.7850. This is a great starting point. Let's see if we can make it better.\n",
        "\n",
        "One of the assumptions for linear regression models is that the data and the features we are giving it are related in a linear fashion, or can be measured with a linear distance metric. If a feature in our dataset has a high variance that's an order of magnitude or more greater than the other features, this could impact the model's ability to learn from other features in the dataset.\n",
        "\n",
        "Correcting for high variance is called normalization. It is one of the possible transformations you do before training a model. Let's check the variance to see if such transformation is needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k9ierg9rag5",
        "outputId": "86857ed9-f582-406d-c15a-aba33b07975b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.var().round(3).to_string())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recency (months)              66.929\n",
            "Frequency (times)             33.830\n",
            "Monetary (c.c. blood)    2114363.700\n",
            "Time (months)                611.147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQdkx6QrrahE"
      },
      "source": [
        "## 9. Log normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NDrfLy7rahG"
      },
      "source": [
        "Monetary (c.c. blood)'s variance is very high in comparison to any other column in the dataset. This means that, unless accounted for, this feature may get more weight by the model (i.e., be seen as more important) than any other feature.\n",
        "\n",
        "One way to correct for high variance is to use log normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXto1v7YrahI",
        "outputId": "5fdf2c47-114f-428f-d0f5-10c113198932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Copy X_train and X_test into X_train_normed and X_test_normed\n",
        "X_train_normed, X_test_normed = X_train.copy(), X_test.copy()\n",
        "\n",
        "# Specify which column to normalize\n",
        "col_to_normalize = X_train_normed.var().idxmax(axis=1)\n",
        "\n",
        "# Log normalization\n",
        "for df_ in [X_train_normed, X_test_normed]:\n",
        "    # Add log normalized column\n",
        "    df_['monetary_log'] = np.log(df_[col_to_normalize])\n",
        "    # Drop the original column\n",
        "    df_.drop(columns=col_to_normalize, inplace=True)\n",
        "\n",
        "# Check the variance for X_train_normed\n",
        "print(X_train_normed.var().round(3).to_string())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recency (months)      66.929\n",
            "Frequency (times)     33.830\n",
            "Time (months)        611.147\n",
            "monetary_log           0.837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCoTHUdcrahS"
      },
      "source": [
        "The variance looks much better now. Notice that now Time (months) has the largest variance, but it's not the orders of magnitude higher than the rest of the variables, so we'll leave it as is.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyS2--G_rahT"
      },
      "source": [
        "## 10. Training the linear regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5o4xwvwrahV"
      },
      "source": [
        "We are now ready to train the linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU-HbEwkrahX",
        "outputId": "c07cdfc2-0bb3-4a22-80e0-7e4fc5aea0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Importing modules\n",
        "from sklearn import linear_model\n",
        "\n",
        "# Instantiate LogisticRegression\n",
        "logreg = linear_model.LogisticRegression(\n",
        "    solver='liblinear',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "logreg.fit(X_train_normed, y_train)\n",
        "\n",
        "# AUC score for tpot model\n",
        "logreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test_normed)[:, 1])\n",
        "print(f'\\nAUC score: {logreg_auc_score:.4f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "AUC score: 0.7890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNV4WY_vrahh"
      },
      "source": [
        "## 11. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tjMiRt-rahj"
      },
      "source": [
        "The demand for blood fluctuates throughout the year. As one prominent example, blood donations slow down during busy holiday seasons. An accurate forecast for the future supply of blood allows for an appropriate action to be taken ahead of time and therefore saving more lives.\n",
        "In this notebook, we explored automatic model selection using TPOT and AUC score we got was 0.7850. This is better than simply choosing 0 all the time (the target incidence suggests that such a model would have 76% success rate). We then log normalized our training data and improved the AUC score by 0.5%. In the field of machine learning, even small improvements in accuracy can be important, depending on the purpose.\n",
        "Another benefit of using logistic regression model is that it is interpretable. We can analyze how much of the variance in the response variable (target) can be explained by other variables in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV3Da0Snrahk",
        "outputId": "3b71d830-8bdc-4425-d567-14b9fb8b5dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "# Sort models based on their AUC score from highest to lowest\n",
        "sorted(\n",
        "    [('tpot', tpot_auc_score.round(4)), ('logreg', logreg_auc_score.round(4))],\n",
        "    key=itemgetter(1),\n",
        "    reverse=True\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('logreg', 0.789), ('tpot', 0.7853)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRImil0csTs0"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}